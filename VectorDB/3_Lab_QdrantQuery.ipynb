{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e89e15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Demo (Python 3.12) - PDF â†’ Qdrant â†’ Retrieve â†’ LLM\n",
      "\n",
      "âœ… Embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "âœ… Vector size detected: 384\n",
      "\n",
      " Inserted 94 chunks into `rag_demo`\n",
      "\n",
      "ðŸ”Ž Retrieved Context (preview):\n",
      " [source=/Users/anandh/projects/Agentic-AI-course/VectorDB/Americas-AI-Action-Plan.pdf page=5]\n",
      "Federal funding to be directed toward states with burdensome AI regulations that waste these \n",
      "funds, but should also not interfere with statesâ€™ rights to pass prudent laws that are not unduly \n",
      "restrictive to innovation. \n",
      "Recommended Policy Actions \n",
      "â€¢ Led by the Office of Science and Technology Policy (OSTP), launch a Request for \n",
      "Information from businesses and the public at large about current Federal regulations \n",
      "that hinder AI innovation and adoption, and work with relevant Federal agencies to take \n",
      "appropriate action. \n",
      "â€¢ Led by the Office of Management and Budget (OMB) and c onsistent with Executive \n",
      "Order 14192 of January 31, 2025, â€œ Unleashing Prosperity Through Deregulation, â€ work \n",
      "with al\n",
      "No question provided.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from uuid import uuid4\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFaceEndpoint\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG\n",
    "# ----------------------------\n",
    "COLLECTION_NAME = \"rag_demo\"\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\", \"http://localhost:6333\")\n",
    "\n",
    "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"  # 384 dims\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Prompt Template\n",
    "# ----------------------------\n",
    "rag_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=(\n",
    "        \"Answer the question using ONLY the context below.\\n\"\n",
    "        \"If the answer is not present, say \\\"I don't know\\\".\\n\\n\"\n",
    "        \"Context:\\n{context}\\n\\n\"\n",
    "        \"Question:\\n{question}\\n\\n\"\n",
    "        \"Answer:\\n\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def load_pdf_documents(pdf_path: str):\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    return loader.load()  # List[Document]\n",
    "\n",
    "\n",
    "def chunk_documents(docs, chunk_size: int = 1000, chunk_overlap: int = 100):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "    )\n",
    "    return splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "def ensure_collection(client: QdrantClient, collection_name: str, vector_size: int):\n",
    "    existing = {c.name for c in client.get_collections().collections}\n",
    "    if collection_name not in existing:\n",
    "        client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE),\n",
    "        )\n",
    "\n",
    "\n",
    "def build_vector_store(client: QdrantClient, collection_name: str, embeddings):\n",
    "    return QdrantVectorStore(\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        embedding=embeddings,\n",
    "    )\n",
    "\n",
    "\n",
    "def build_llm():\n",
    "    # Minimal params to avoid unsupported param errors on hosted endpoints.\n",
    "    return HuggingFaceEndpoint(\n",
    "        repo_id=\"Qwen/Qwen3-30B-A3B\",\n",
    "        max_new_tokens=512,\n",
    "        huggingfacehub_api_token=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\"),\n",
    "    )\n",
    "\n",
    "\n",
    "def insert_pdf(vector_store: QdrantVectorStore):\n",
    "    pdf_path = input(\"Enter path to PDF file: \").strip()\n",
    "    if not pdf_path:\n",
    "        print(\"No path provided.\")\n",
    "        return\n",
    "\n",
    "    docs = load_pdf_documents(pdf_path)\n",
    "\n",
    "    # Attach source filename\n",
    "    for d in docs:\n",
    "        d.metadata = d.metadata or {}\n",
    "        d.metadata[\"source\"] = pdf_path\n",
    "\n",
    "    chunks = chunk_documents(docs)\n",
    "\n",
    "    ids = [str(uuid4()) for _ in chunks]\n",
    "    vector_store.add_documents(documents=chunks, ids=ids)\n",
    "\n",
    "    print(f\" Inserted {len(chunks)} chunks into `{COLLECTION_NAME}`\")\n",
    "\n",
    "\n",
    "def fetch_context(vector_store: QdrantVectorStore, k: int = 5) -> str | None:\n",
    "    query_text = input(\"Enter search query: \").strip()\n",
    "    if not query_text:\n",
    "        print(\"No query provided.\")\n",
    "        return None\n",
    "\n",
    "    results = vector_store.similarity_search(query_text, k=k)\n",
    "    if not results:\n",
    "        print(\"No matching results found.\")\n",
    "        return None\n",
    "\n",
    "    lines = []\n",
    "    for r in results:\n",
    "        src = r.metadata.get(\"source\", \"unknown\")\n",
    "        page = r.metadata.get(\"page\", \"n/a\")\n",
    "        lines.append(f\"[source={src} page={page}]\\n{r.page_content}\")\n",
    "\n",
    "    context = \"\\n\\n---\\n\\n\".join(lines)\n",
    "    print(\"\\nðŸ”Ž Retrieved Context (preview):\\n\", context[:800])\n",
    "    return context\n",
    "\n",
    "\n",
    "def chat_rag(llm, vector_store: QdrantVectorStore):\n",
    "    context = fetch_context(vector_store)\n",
    "    if not context:\n",
    "        return\n",
    "\n",
    "    question = input(\"\\nEnter your question about the retrieved text: \").strip()\n",
    "    if not question:\n",
    "        print(\"No question provided.\")\n",
    "        return\n",
    "\n",
    "    prompt = rag_prompt_template.format(context=context, question=question)\n",
    "\n",
    "    answer = llm.invoke(prompt)\n",
    "    print(\"\\nðŸ¤– AI Response:\\n\", answer)\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"RAG Demo (Python 3.12) - PDF â†’ Qdrant â†’ Retrieve â†’ LLM\\n\")\n",
    "\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n",
    "\n",
    "    # Auto-detect vector size\n",
    "    vector_size = len(embeddings.embed_query(\"dimension check\"))\n",
    "    print(f\"âœ… Embedding model: {EMBED_MODEL}\")\n",
    "    print(f\"âœ… Vector size detected: {vector_size}\\n\")\n",
    "\n",
    "    client = QdrantClient(url=QDRANT_URL)\n",
    "    ensure_collection(client, COLLECTION_NAME, vector_size)\n",
    "\n",
    "    vector_store = build_vector_store(client, COLLECTION_NAME, embeddings)\n",
    "    llm = build_llm()\n",
    "\n",
    "    while True:\n",
    "        choice = input(\n",
    "            \"\\nChoose an action:\\n\"\n",
    "            \"1. Insert Text from PDF\\n\"\n",
    "            \"2. Fetch & Interact with AI\\n\"\n",
    "            \"3. Exit\\n\"\n",
    "            \"Enter choice: \"\n",
    "        ).strip()\n",
    "\n",
    "        if choice == \"1\":\n",
    "            insert_pdf(vector_store)\n",
    "        elif choice == \"2\":\n",
    "            chat_rag(llm, vector_store)\n",
    "        elif choice == \"3\":\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice. Please enter 1, 2, or 3.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd909a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
