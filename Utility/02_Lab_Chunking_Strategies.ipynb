{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3d6db46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "chunk_size=10, overlap=2\n",
      "Total chunks created: 6\n",
      "\n",
      "Top Matches:\n",
      "\n",
      "Chunk #2\n",
      "Score: 0.239\n",
      "Interpretation: Probably irrelevant\n",
      "Text: databases, filesystems, or APIs. When you chunk documents poorly, retrieval\n",
      "\n",
      "Chunk #3\n",
      "Score: 0.239\n",
      "Interpretation: Probably irrelevant\n",
      "Text: poorly, retrieval returns incomplete context. Smaller chunks improve precision but\n",
      "\n",
      "Chunk #4\n",
      "Score: 0.202\n",
      "Interpretation: Probably irrelevant\n",
      "Text: precision but may lose context. Larger chunks preserve context but\n",
      "\n",
      "Score Gap (Top1 - Top2): 0.000\n",
      "→ Weak separation (chunking may need tuning)\n",
      "\n",
      "======================================================================\n",
      "chunk_size=25, overlap=5\n",
      "Total chunks created: 3\n",
      "\n",
      "Top Matches:\n",
      "\n",
      "Chunk #1\n",
      "Score: 0.218\n",
      "Interpretation: Probably irrelevant\n",
      "Text: MCP lets models call tools. Tools can be databases, filesystems, or APIs. When you chunk documents poorly, retrieval returns incomplete context. Smaller chunks improve precision\n",
      "\n",
      "Chunk #2\n",
      "Score: 0.182\n",
      "Interpretation: Probably irrelevant\n",
      "Text: context. Smaller chunks improve precision but may lose context. Larger chunks preserve context but may reduce recall. Overlap can help continuity between chunks.\n",
      "\n",
      "Chunk #3\n",
      "Score: 0.000\n",
      "Interpretation: Probably irrelevant\n",
      "Text: continuity between chunks.\n",
      "\n",
      "Score Gap (Top1 - Top2): 0.037\n",
      "→ Weak separation (chunking may need tuning)\n",
      "\n",
      "======================================================================\n",
      "chunk_size=40, overlap=10\n",
      "Total chunks created: 2\n",
      "\n",
      "Top Matches:\n",
      "\n",
      "Chunk #1\n",
      "Score: 0.253\n",
      "Interpretation: Probably irrelevant\n",
      "Text: MCP lets models call tools. Tools can be databases, filesystems, or APIs. When you chunk documents poorly, retrieval returns incomplete context. Smaller chunks improve precision but may lose context. Larger chunks preserve context but may reduce recall. Overlap can help\n",
      "\n",
      "Chunk #2\n",
      "Score: 0.098\n",
      "Interpretation: Probably irrelevant\n",
      "Text: chunks preserve context but may reduce recall. Overlap can help continuity between chunks.\n",
      "\n",
      "Score Gap (Top1 - Top2): 0.155\n",
      "→ Strong separation (good chunk discrimination)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Demonstrate how chunk_size affects retrieval.\n",
    "NOW includes score interpretation ranges and gap analysis.\n",
    "\n",
    "Score Ranges:\n",
    "0.75 – 1.0   -> Very strong semantic match\n",
    "0.60 – 0.75  -> Good match\n",
    "0.45 – 0.60  -> Weak/moderate\n",
    "< 0.40       -> Probably irrelevant\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import logging\n",
    "from collections import Counter\n",
    "\n",
    "# ---------------- LOGGING ----------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\"\n",
    ")\n",
    "log = logging.getLogger(\"chunking-eval\")\n",
    "\n",
    "# ---------------- SAMPLE DATA ----------------\n",
    "DOC = (\n",
    "    \"MCP lets models call tools. Tools can be databases, filesystems, or APIs.\\n\"\n",
    "    \"When you chunk documents poorly, retrieval returns incomplete context.\\n\"\n",
    "    \"Smaller chunks improve precision but may lose context.\\n\"\n",
    "    \"Larger chunks preserve context but may reduce recall.\\n\"\n",
    "    \"Overlap can help continuity between chunks.\\n\"\n",
    ")\n",
    "\n",
    "QUERY = \"How does chunk size affect retrieval context?\"\n",
    "\n",
    "# ---------------- SCORE INTERPRETATION ----------------\n",
    "def interpret_score(score: float) -> str:\n",
    "    if score >= 0.75:\n",
    "        return \"Very strong semantic match\"\n",
    "    elif score >= 0.60:\n",
    "        return \"Good match\"\n",
    "    elif score >= 0.45:\n",
    "        return \"Weak / moderate match\"\n",
    "    else:\n",
    "        return \"Probably irrelevant\"\n",
    "\n",
    "# ---------------- CHUNKING ----------------\n",
    "def chunk_text(text: str, chunk_size: int, overlap: int):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    i = 0\n",
    "\n",
    "    while i < len(words):\n",
    "        chunk = words[i:i+chunk_size]\n",
    "        chunks.append(\" \".join(chunk))\n",
    "        i += max(1, chunk_size - overlap)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# ---------------- VECTOR ----------------\n",
    "def bow_vector(text: str) -> Counter:\n",
    "    return Counter(w.lower().strip(\".,!?\") for w in text.split())\n",
    "\n",
    "def cosine(a: Counter, b: Counter) -> float:\n",
    "    dot = sum(a[k] * b.get(k, 0) for k in a)\n",
    "    na = math.sqrt(sum(v*v for v in a.values()))\n",
    "    nb = math.sqrt(sum(v*v for v in b.values()))\n",
    "    return dot / (na * nb + 1e-9)\n",
    "\n",
    "# ---------------- RETRIEVAL ----------------\n",
    "def top_chunks(chunks, query, k=3):\n",
    "    qv = bow_vector(query)\n",
    "    scored = []\n",
    "\n",
    "    for idx, c in enumerate(chunks):\n",
    "        cv = bow_vector(c)\n",
    "        score = cosine(cv, qv)\n",
    "        scored.append((score, idx + 1, c))\n",
    "\n",
    "    scored.sort(reverse=True, key=lambda x: x[0])\n",
    "    return scored[:k]\n",
    "\n",
    "# ---------------- RUN EXPERIMENT ----------------\n",
    "def run(chunk_size: int, overlap: int):\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"chunk_size={chunk_size}, overlap={overlap}\")\n",
    "\n",
    "    chunks = chunk_text(DOC, chunk_size, overlap)\n",
    "    print(f\"Total chunks created: {len(chunks)}\")\n",
    "\n",
    "    hits = top_chunks(chunks, QUERY, k=3)\n",
    "\n",
    "    print(\"\\nTop Matches:\")\n",
    "    for score, idx, chunk in hits:\n",
    "        interpretation = interpret_score(score)\n",
    "        print(f\"\\nChunk #{idx}\")\n",
    "        print(f\"Score: {score:.3f}\")\n",
    "        print(f\"Interpretation: {interpretation}\")\n",
    "        print(f\"Text: {chunk}\")\n",
    "\n",
    "    # Score gap analysis\n",
    "    if len(hits) >= 2:\n",
    "        gap = hits[0][0] - hits[1][0]\n",
    "        print(f\"\\nScore Gap (Top1 - Top2): {gap:.3f}\")\n",
    "        if gap > 0.15:\n",
    "            print(\"→ Strong separation (good chunk discrimination)\")\n",
    "        elif gap > 0.05:\n",
    "            print(\"→ Moderate separation\")\n",
    "        else:\n",
    "            print(\"→ Weak separation (chunking may need tuning)\")\n",
    "\n",
    "# ---------------- MAIN ----------------\n",
    "def main():\n",
    "    run(chunk_size=10, overlap=2)\n",
    "    run(chunk_size=25, overlap=5)\n",
    "    run(chunk_size=40, overlap=10)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
